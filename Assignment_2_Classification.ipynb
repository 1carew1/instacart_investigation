{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "***\n",
    "* [Aim](#aim)\n",
    "* [Code Setup](#code-setup)\n",
    "* [Data Import](#data-import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim <a class=\"anchor\" id=\"aim\"></a>\n",
    "***\n",
    "\n",
    "The aim of this notebook is to perform Classification on the Instacart Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup <a class=\"anchor\" id=\"code-setup\"></a>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instacart_dir = \"instacart_2017_05_01/\"\n",
    "my_orders_file = \"my_orders.csv\"\n",
    "products_file = \"products.csv\"\n",
    "aisles_file = \"aisles.csv\"\n",
    "departments_file = \"departments.csv\"\n",
    "orders_products_prior_file = \"my_order_products__prior.csv\"\n",
    "orders_products_train_file = \"my_order_products__train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(file_name):\n",
    "    return pd.read_csv(instacart_dir + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the relative reoder frequency of orders\n",
    "def relative_reoder_frequency(os_ps):\n",
    "    reoder_freq_per_prod_dict = {}\n",
    "    unique_prod_ids = os_ps.product_id.unique().tolist()\n",
    "    unique_order_ids = os_ps.order_id.unique().tolist()\n",
    "    for prod_id in unique_prod_ids:\n",
    "        orders_for_product = os_ps.query(\"product_id == \" + str(prod_id))\n",
    "        number_of_times_reordered = orders_for_product.query(\"reordered == 1\").shape[0]\n",
    "        unique_orders_less_one = len(unique_order_ids) -1\n",
    "        rel_reorder = 0\n",
    "        if unique_orders_less_one != 0:\n",
    "            rel_reorder = round((number_of_times_reordered/unique_orders_less_one),3)\n",
    "        reoder_freq_per_prod_dict[prod_id] = rel_reorder\n",
    "    return reoder_freq_per_prod_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the relative product count\n",
    "def product_relative_count(os_ps):\n",
    "    rel_prod_count_dict = {}\n",
    "    unique_prod_ids = os_ps.product_id.unique().tolist()\n",
    "    unique_order_ids = os_ps.order_id.unique().tolist()\n",
    "    for prod_id in unique_prod_ids:\n",
    "        orders_for_product = os_ps.query(\"product_id == \" + str(prod_id))\n",
    "        order_ids_for_these = orders_for_product.order_id.unique().tolist()\n",
    "        all_of_these_orders = os_ps[os_ps['order_id'].isin(order_ids_for_these)]\n",
    "        prod_count_for_each_order = all_of_these_orders.groupby(\"order_id\").size().reset_index(name=\"product_count\")\n",
    "        order_size_counts = prod_count_for_each_order.product_count.tolist()\n",
    "        relative_order_count = 0\n",
    "        for order_size in order_size_counts :\n",
    "            relative_order_count = relative_order_count + 1/order_size\n",
    "        relative_order_size = round(relative_order_count/len(unique_order_ids),3)\n",
    "        rel_prod_count_dict[prod_id] = relative_order_size\n",
    "    return rel_prod_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def products_reoder_rate_mean(p_r_r_d):\n",
    "    reorder_dict = {}\n",
    "    for prod_id, rates in p_r_r_d.items():\n",
    "        sum_of_rates = sum(rates)\n",
    "        avg_rate = round(sum_of_rates/len(rates),3)\n",
    "        reorder_dict[prod_id] = avg_rate\n",
    "    return reorder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Linear Regression get the reorder rate based on position in cart\n",
    "def obtain_redorder_rate_per_product_on_cart_position(os_ps):\n",
    "    reorder_rate_to_position = (os_ps\n",
    "                            .groupby(\"add_to_cart_order\")[\"reordered\"]\n",
    "                            .sum()\n",
    "                            .reset_index(name=\"reordered_count\")\n",
    "                           )\n",
    "    total_reorder_count = reorder_rate_to_position.reordered_count.sum()\n",
    "    \n",
    "    notreordered_orders_products = os_ps.query(\"reordered == 0\")\n",
    "    notreorder_rate_to_position = (notreordered_orders_products\n",
    "                            .groupby(\"add_to_cart_order\")\n",
    "                            .size()\n",
    "                            .reset_index(name=\"not_reordered_count\")\n",
    "                           )\n",
    "    total_notreorder_count = notreorder_rate_to_position.not_reordered_count.sum()\n",
    "    order_rates = reorder_rate_to_position.merge(notreorder_rate_to_position, on=\"add_to_cart_order\", how=\"left\")\n",
    "    order_rates = order_rates.fillna(0)\n",
    "    order_rates['reorder_rate'] = order_rates['reordered_count'] /(order_rates['not_reordered_count'] + order_rates['reordered_count'])\n",
    "    x_training_set = order_rates.as_matrix(['add_to_cart_order'])\n",
    "    y_training_set = order_rates.as_matrix(['reorder_rate'])\n",
    "\n",
    "    # Use a line as a quadratic gave negative predictions at cart position of 30 and onwards\n",
    "    # The line gives negative rate after a position of 36 and onwards\n",
    "    poly = PolynomialFeatures(degree=1)\n",
    "    x_training_set_transform = poly.fit_transform(x_training_set)\n",
    "\n",
    "    reorder_rate_reg_model = linear_model.LinearRegression()\n",
    "    reorder_rate_reg_model.fit(x_training_set_transform,y_training_set)\n",
    "    \n",
    "    products_reoder_rate_dict = {}\n",
    "    distinct_products = os_ps.product_id.unique().tolist()\n",
    "    for product_id in distinct_products:\n",
    "        orders_for_product = os_ps.query(\"product_id == \" + str(product_id))\n",
    "        add_to_cart_order_list = orders_for_product.add_to_cart_order.tolist()\n",
    "        reorder_rate_list = []\n",
    "        for add_to_cart_order in add_to_cart_order_list :\n",
    "            pos_to_test = add_to_cart_order\n",
    "            position_to_test = poly.fit_transform(pos_to_test)\n",
    "            preditced_reorder_rate_from_position = reorder_rate_reg_model.predict(position_to_test)[0][0]\n",
    "            reorder_rate_list.append(preditced_reorder_rate_from_position)\n",
    "        products_reoder_rate_dict[product_id] = reorder_rate_list\n",
    "    return products_reoder_rate_mean(products_reoder_rate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_orders_products(df):\n",
    "    return df.copy().merge(orders_products, on=\"order_id\")[[\"order_id\", \"product_id\", \"add_to_cart_order\",\"order_number\", \"reordered\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_empty_dfs_with_columns(ords_prods):\n",
    "    number_of_orders = len(ords_prods.order_id.unique().tolist())\n",
    "    \n",
    "    product_mix_column_names = []\n",
    "    feature_column_names = []\n",
    "    # This will be every product in all the orders we intend to use for prediction\n",
    "    product_ids = ords_prods.product_id.unique().tolist()\n",
    "    product_ids.sort()\n",
    "    for prod_id in product_ids:\n",
    "        feature_column_names.append(str(prod_id) + \"_rel_count\")\n",
    "        feature_column_names.append(str(prod_id) + \"_reorder_freq\")\n",
    "        feature_column_names.append(str(prod_id) + \"_reorder_rate\")\n",
    "        product_mix_column_names.append(str(prod_id))\n",
    "\n",
    "    # Create Data Frame - with number of rows equal to previous orders - 1\n",
    "    product_mix = pd.DataFrame(columns=product_mix_column_names, index=range(number_of_orders - 1))\n",
    "    features = pd.DataFrame(columns=feature_column_names, index=range(number_of_orders - 1))\n",
    "    # Create the test data frames\n",
    "    test_product_mix = pd.DataFrame(columns=product_mix_column_names, index=range(1))\n",
    "    test_features = pd.DataFrame(columns=feature_column_names, index=range(1))\n",
    "    \n",
    "    # Populate the data frames with 0s\n",
    "    for column_name in product_mix_column_names:\n",
    "        product_mix[column_name] = 0\n",
    "        test_product_mix[column_name] = 0\n",
    "    for column_name in feature_column_names:\n",
    "        features[column_name] = 0\n",
    "        test_features[column_name] = 0\n",
    "    return (features, product_mix, test_features, test_product_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_product_mix(product_ids, product_mix_df, location):\n",
    "    new_prod_mix = product_mix_df.copy()\n",
    "    for prod_id in product_ids:\n",
    "        prod_string_id = str(prod_id)\n",
    "        product_column_list = new_prod_mix.columns.values\n",
    "        # We cannot predict what products we have not seen\n",
    "        if prod_string_id in product_column_list:\n",
    "            new_prod_mix.iloc[location, new_prod_mix.columns.get_loc(prod_string_id)] = 1\n",
    "    return new_prod_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_features(ords, features, location):\n",
    "    new_featutres = features.copy()\n",
    "    products_reoder_rate = obtain_redorder_rate_per_product_on_cart_position(ords)\n",
    "    product_reoder_freq = relative_reoder_frequency(ords)\n",
    "    rel_prod_count = product_relative_count(ords)\n",
    " \n",
    "    # Assign Feature Values to df\n",
    "    for prod_id in rel_prod_count.keys():\n",
    "        prod_str_id = str(prod_id)\n",
    "        new_featutres.iloc[location, new_featutres.columns.get_loc(prod_str_id + \"_reorder_freq\")] = product_reoder_freq.get(prod_id)\n",
    "        new_featutres.iloc[location, new_featutres.columns.get_loc(prod_str_id + \"_rel_count\")] = rel_prod_count.get(prod_id)\n",
    "        new_featutres.iloc[location, new_featutres.columns.get_loc(prod_str_id + \"_reorder_rate\")] = products_reoder_rate.get(prod_id)\n",
    "    return new_featutres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Massive function for crunching the data and putting it into the train and test formats we want\n",
    "def obtain_features_and_product_mix(training_orders, test_order):\n",
    "    number_of_test_orders = test_order.shape[0]\n",
    "    if number_of_test_orders != 1:\n",
    "        raise ValueError('You should only have one next product mix to predict')\n",
    "    \n",
    "    number_of_orders = training_orders.shape[0]\n",
    "    \n",
    "    training_orders_prod = merge_orders_products(training_orders)    \n",
    "    test_orders_prod = merge_orders_products(test_order)\n",
    "    \n",
    "    features, product_mix, test_features, test_product_mix = generate_empty_dfs_with_columns(training_orders_prod)\n",
    "    \n",
    "    # For the Training DFs\n",
    "    # Fill the feature and product mix train dfs\n",
    "    for i in range(2, number_of_orders + 1):\n",
    "        orders_including_current = training_orders.copy().head(i)\n",
    "        orders_before_current = orders_including_current.copy().head(i - 1)\n",
    "        # This is the position of the DF we will fill, usual i loop headaches \n",
    "        j = i - 2\n",
    "        \n",
    "        orders_before_current = merge_orders_products(orders_before_current)\n",
    "        current_order = orders_including_current.sort_values(\"order_id\", ascending=False).head(1)\n",
    "        current_order_products = merge_orders_products(current_order)\n",
    "\n",
    "        products_for_current_order = current_order_products.product_id.unique().tolist()\n",
    "        \n",
    "        # Assign Features\n",
    "        features = populate_features(orders_before_current, features, j)\n",
    "        \n",
    "        # Assign Product Mix\n",
    "        product_mix = populate_product_mix(products_for_current_order, product_mix, j)\n",
    "\n",
    "        \n",
    "    # For the Test DFs\n",
    "    # Assign test features to test df\n",
    "    test_features = populate_features(training_orders_prod, test_features, 0)\n",
    "    # Assign product mix to test df\n",
    "    products_for_test_order = test_orders_prod.product_id.unique().tolist()\n",
    "    test_product_mix = populate_product_mix(products_for_test_order, test_product_mix, 0)\n",
    "    \n",
    "    return (features, product_mix, test_features, test_product_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_product_from_ids(arr, product_id_list, products):\n",
    "    product_ids = train_product_mix.columns.values\n",
    "    predicted_product_ids = []\n",
    "    for index, value in enumerate(arr):\n",
    "        if(value == 1):\n",
    "            predicted_product_ids.append(product_id_list[index])\n",
    "    found_products = products[products['product_id'].isin(predicted_product_ids)].sort_values(\"product_id\", ascending=True)\n",
    "    return found_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  20 users with a corresponding entry in order history list who's length is also 20\n"
     ]
    }
   ],
   "source": [
    "orders = read_csv_file(my_orders_file)\n",
    "products = read_csv_file(products_file)\n",
    "aisles = read_csv_file(aisles_file)\n",
    "orders_products_prior = read_csv_file(orders_products_prior_file)\n",
    "orders_products_train = read_csv_file(orders_products_train_file)\n",
    "orders_products = pd.concat([orders_products_prior, orders_products_train])\n",
    "orders_per_user = []\n",
    "user_ids = orders.user_id.unique().tolist()\n",
    "for user_id in user_ids:\n",
    "    orders_per_user.append(orders.query(\"user_id == \" + str(user_id)))\n",
    "print(\"There are \", len(user_ids), \"users with a corresponding entry in order history list who's length is also\", len(orders_per_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for Single User\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This user 47562 has  89  orders\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>790798</td>\n",
       "      <td>2178653</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>790799</td>\n",
       "      <td>3355208</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>790800</td>\n",
       "      <td>213516</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>790801</td>\n",
       "      <td>1498655</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>790802</td>\n",
       "      <td>324368</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  order_id  user_id eval_set  order_number  order_dow  \\\n",
       "26      790798   2178653    47562    prior             1          4   \n",
       "27      790799   3355208    47562    prior             2          2   \n",
       "28      790800    213516    47562    prior             3          4   \n",
       "29      790801   1498655    47562    prior             4          2   \n",
       "30      790802    324368    47562    prior             5          3   \n",
       "\n",
       "    order_hour_of_day  days_since_prior_order  \n",
       "26                  9                     NaN  \n",
       "27                  9                     5.0  \n",
       "28                  7                     2.0  \n",
       "29                  7                     5.0  \n",
       "30                  8                     1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_user_order_df = orders_per_user[4]\n",
    "user_id = specific_user_order_df.user_id.tolist()[0]\n",
    "print(\"This user\", user_id , \"has \", specific_user_order_df.shape[0], \" orders\")\n",
    "specific_user_order_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>790831</td>\n",
       "      <td>98406</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>790819</td>\n",
       "      <td>117008</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>790866</td>\n",
       "      <td>128325</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>790827</td>\n",
       "      <td>137193</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>790847</td>\n",
       "      <td>139812</td>\n",
       "      <td>47562</td>\n",
       "      <td>prior</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  order_id  user_id eval_set  order_number  order_dow  \\\n",
       "59      790831     98406    47562    prior            34          3   \n",
       "47      790819    117008    47562    prior            22          5   \n",
       "94      790866    128325    47562    prior            69          4   \n",
       "55      790827    137193    47562    prior            30          3   \n",
       "75      790847    139812    47562    prior            50          2   \n",
       "\n",
       "    order_hour_of_day  days_since_prior_order  \n",
       "59                  8                     2.0  \n",
       "47                  9                     1.0  \n",
       "94                 15                     3.0  \n",
       "55                  8                     5.0  \n",
       "75                 11                     1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_order_number = specific_user_order_df.order_number.max()\n",
    "next_user_order = specific_user_order_df.query(\"order_number == \" + str(max_order_number))\n",
    "train_user_orders = specific_user_order_df.query(\"order_number < \" + str(max_order_number)).sort_values(\"order_id\", ascending=True)\n",
    "train_user_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dc817b58d78f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_product_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_product_mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobtain_features_and_product_mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_user_orders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_user_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-6a11387e236b>\u001b[0m in \u001b[0;36mobtain_features_and_product_mix\u001b[0;34m(training_orders, test_order)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Assign Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morders_before_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Assign Product Mix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ea34064c5072>\u001b[0m in \u001b[0;36mpopulate_features\u001b[0;34m(ords, features, location)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mproducts_reoder_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobtain_redorder_rate_per_product_on_cart_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mproduct_reoder_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelative_reoder_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrel_prod_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_relative_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Assign Feature Values to df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ac214ef0781c>\u001b[0m in \u001b[0;36mproduct_relative_count\u001b[0;34m(os_ps)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0munique_order_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_ps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprod_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_prod_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0morders_for_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_ps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"product_id == \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0morder_ids_for_these\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morders_for_product\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mall_of_these_orders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_ps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mos_ps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder_ids_for_these\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2293\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"expr must be a string to be evaluated, {0} given\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2296\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_features, train_product_mix, test_features, test_product_mix = obtain_features_and_product_mix(train_user_orders, next_user_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='poly'))\n",
    "clf.fit(train_features, train_product_mix)\n",
    "clf.predict(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, prediction only seems to be happening in the 2nd columns (index of 1), 6th and 7th columns (index of 5 and 6 respectively). This may be a result of some of the features bringing the predictors to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_product_mix.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(train_features, train_product_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 4 training cases, it predicted one of the training cases fully. Which given there were only 5 test orders so only 4 of which can be predicted, this is not too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_product_mix = clf.predict(test_features).flatten().tolist()\n",
    "print(predicted_product_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_product_mix = test_product_mix.as_matrix()[0].tolist()\n",
    "print(actual_product_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we score the test data against the predicted we get a 0 however, if we looks at what it did predict correctly, it go 2 of the next ordered product predicted and miss predicted 1 so this is not a bad result. The 2nd, 6th and 7th columns were all populated so the model seems biased towards though, though the results were quite good.\n",
    "\n",
    "Let's look at what the products actually were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_predicted_products = find_product_from_ids(predicted_product_mix, train_product_mix.columns.values, products)\n",
    "found_predicted_products.head(found_predicted_products.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_products = find_product_from_ids(actual_product_mix, train_product_mix.columns.values, products)\n",
    "actual_products.head(actual_products.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall the classification seems to have worked well in that this customer did buy a snack and washing powder again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification for All Orders\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order_number = orders.order_number.max()\n",
    "next_order = orders.query(\"order_number == \" + str(max_order_number))\n",
    "train_orders = orders.query(\"order_number < \" + str(max_order_number)).sort_values(\"order_id\", ascending=True)\n",
    "train_user_orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_product_mix, test_features, test_product_mix = obtain_features_and_product_mix(train_orders, next_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "***\n",
    "Wanted to user a neural network but didn't have enough data on a per user basis to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial EDA for Classification\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_user_order_df = orders_per_user[0]\n",
    "user_id = specific_user_order_df.user_id.tolist()[0]\n",
    "print(\"This user\", user_id , \"has \", specific_user_order_df.shape[0], \" orders\")\n",
    "specific_user_order_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_order_number = specific_user_order_df.order_number.max()\n",
    "next_user_order = specific_user_order_df.query(\"order_number == \" + str(max_order_number))\n",
    "train_user_orders = specific_user_order_df.query(\"order_number < \" + str(max_order_number))\n",
    "next_user_order.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join in the Order Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_orders_prod = train_user_orders.merge(orders_products, on=\"order_id\")[[\"order_id\", \"product_id\", \"add_to_cart_order\",\"order_number\", \"reordered\"]]\n",
    "train_user_orders_prod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reorder Rate vs Add to Cart Investigation\n",
    "***\n",
    "Note below was used to aid in the creation of the : obtain_redorder_rate_per_product_on_cart_position function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_rate_to_position = (orders_products\n",
    "                            .groupby(\"add_to_cart_order\")[\"reordered\"]\n",
    "                            .sum()\n",
    "                            .reset_index(name=\"reordered_count\")\n",
    "                           )\n",
    "total_reorder_count = reorder_rate_to_position.reordered_count.sum()\n",
    "print(\"Total times products reordered :\", total_reorder_count)\n",
    "reorder_rate_to_position.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "reorder_rate_to_position['reordered_count'].plot.bar()\n",
    "ax.set_xticklabels(reorder_rate_to_position[\"add_to_cart_order\"], rotation='horizontal')\n",
    "plt.title(\"Reorder Count vs Position in Cart\")\n",
    "plt.ylabel(\"Number of Reorders for that position\")\n",
    "plt.xlabel(\"Cart Position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graphs shows that the item that is first in the cart is the most reordered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not Reordered to Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notreordered_orders_products = orders_products.query(\"reordered == 0\")\n",
    "notreorder_rate_to_position = (notreordered_orders_products\n",
    "                            .groupby(\"add_to_cart_order\")\n",
    "                            .size()\n",
    "                            .reset_index(name=\"not_reordered_count\")\n",
    "                           )\n",
    "total_notreorder_count = notreorder_rate_to_position.not_reordered_count.sum()\n",
    "print(\"Total times products not reordered :\", total_notreorder_count)\n",
    "notreorder_rate_to_position.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "notreorder_rate_to_position['not_reordered_count'].plot.bar()\n",
    "ax.set_xticklabels(notreorder_rate_to_position[\"add_to_cart_order\"], rotation='horizontal')\n",
    "plt.title(\"Not Reorder Count vs Position in Cart\")\n",
    "plt.ylabel(\"Number of Orders for that position there were not a reorder\")\n",
    "plt.xlabel(\"Cart Position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_rates = notreorder_rate_to_position.merge(reorder_rate_to_position, on=\"add_to_cart_order\")\n",
    "order_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_rates['reorder_rate'] = order_rates['reordered_count'] /(order_rates['not_reordered_count'] + order_rates['reordered_count'])\n",
    "order_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(order_rates[\"add_to_cart_order\"], order_rates['reorder_rate'], \"-o\")\n",
    "plt.title(\"Reorder Rate by Cart Position\")\n",
    "plt.xlabel(\"Cart Position\")\n",
    "plt.ylabel(\"Reorder Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Model with 1st Order Polynomial - Add to Cart Reorder Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the graph breaks down after about the 20th position in the cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training_set = order_rates.as_matrix(['add_to_cart_order'])\n",
    "y_training_set = order_rates.as_matrix(['reorder_rate'])\n",
    "\n",
    "# Use a line as a quadratic gave negative predictions at cart position of 30 and onwards\n",
    "# The line gives negative rate after a position of 36 and onwards\n",
    "poly = PolynomialFeatures(degree=1)\n",
    "x_training_set_transform = poly.fit_transform(x_training_set)\n",
    "\n",
    "reorder_rate_reg_model = linear_model.LinearRegression()\n",
    "reorder_rate_reg_model.fit(x_training_set_transform,y_training_set)\n",
    "\n",
    "train_score = reorder_rate_reg_model.score(x_training_set_transform, y_training_set)\n",
    "\n",
    "pos_to_test = 35\n",
    "position_to_test = poly.fit_transform(pos_to_test)\n",
    "preditced_reorder_rate_from_position = reorder_rate_reg_model.predict(position_to_test)[0][0]\n",
    "\n",
    "print(\"The model score :\", train_score, \" using the training data and for a cart position of :\",pos_to_test, \n",
    "      \"the model preditced a reorder rate of :\", preditced_reorder_rate_from_position)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
