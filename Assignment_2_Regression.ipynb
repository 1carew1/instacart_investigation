{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "***\n",
    "* [Aim](#aim)\n",
    "* [Code Setup](#code-setup)\n",
    "* [Data Import](#data-import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim <a class=\"anchor\" id=\"aim\"></a>\n",
    "***\n",
    "\n",
    "The aim of this notebook is to perform Regression on the Instacart Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Setup <a class=\"anchor\" id=\"code-setup\"></a>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instacart_dir = \"instacart_2017_05_01/\"\n",
    "my_orders_file = \"my_orders.csv\"\n",
    "products_file = \"products.csv\"\n",
    "aisles_file = \"aisles.csv\"\n",
    "departments_file = \"departments.csv\"\n",
    "orders_products_prior_file = \"my_order_products__prior.csv\"\n",
    "orders_products_train_file = \"my_order_products__train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"paper\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(file_name):\n",
    "    return pd.read_csv(instacart_dir + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = read_csv_file(my_orders_file)\n",
    "products = read_csv_file(products_file)\n",
    "aisles = read_csv_file(aisles_file)\n",
    "orders_products_prior = read_csv_file(orders_products_prior_file)\n",
    "orders_products_train = read_csv_file(orders_products_train_file)\n",
    "orders_products = pd.concat([orders_products_prior, orders_products_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_products(train, test):\n",
    "    train_orders_prod = train.merge(orders_products, on=\"order_id\")\n",
    "    train_orders_prod = train_orders_prod.merge(products, on=\"product_id\")\n",
    "\n",
    "    test_orders_prod = test.merge(orders_products, on=\"order_id\")\n",
    "    test_orders_prod = test_orders_prod.merge(products, on=\"product_id\")\n",
    "    \n",
    "    return (train_orders_prod, test_orders_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_to_next_order(order_df):\n",
    "    orders = order_df.copy()\n",
    "    orders[\"days_to_next_order\"] = np.nan\n",
    "    for index, cur_order in orders.iterrows():\n",
    "        next_order_number = cur_order.order_number + 1\n",
    "        user_id = cur_order.user_id\n",
    "        next_order_df = orders.query(\"user_id == \" + str(user_id) + \" and  order_number == \" + str(next_order_number))\n",
    "        if(next_order_df.shape[0] == 1):\n",
    "            next_order = next_order_df.iloc[0]\n",
    "            days_to_next_order = next_order.days_since_prior_order\n",
    "            if(np.isfinite(days_to_next_order)):\n",
    "                orders.loc[index, 'days_to_next_order'] = days_to_next_order\n",
    "    return orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_columns(next_one):\n",
    "    list = [\"order_id\", \"days_to_next_order\", next_one]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_features_and_value(df_train, df_test):\n",
    "    # Target\n",
    "    y_train = df_train['days_to_next_order'].copy()\n",
    "    X_train = df_train.copy() \n",
    "    # Feature\n",
    "    X_train.drop(['days_to_next_order'], axis=1, inplace=True)\n",
    "\n",
    "    # Testing\n",
    "    y_test = df_test['days_to_next_order'].copy()\n",
    "    X_test = df_test.copy() \n",
    "    # Feature\n",
    "    X_test.drop(['days_to_next_order'], axis=1, inplace=True)\n",
    "    return (X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_each_aisle_to_df(df):\n",
    "    df_aisles = df.copy().merge(aisles, on=\"aisle_id\")\n",
    "    for index, row in aisles.iterrows():\n",
    "        aisle_name = row.aisle\n",
    "        df_aisles[aisle_name] = 0\n",
    "    return df_aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_each_product_to_df(df, popular_products):\n",
    "    df_products = df.copy().merge(products, on=\"product_id\")\n",
    "    for index, row in popular_products.iterrows():\n",
    "        product_name = row.product_name\n",
    "        df_products[product_name] = 0\n",
    "    return df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_order_in_df(df_ordered, item_name, cols_to_drop):\n",
    "    # Create new df with only the column names\n",
    "    df = df_ordered.copy()\n",
    "    df.drop(df.index, inplace=True)\n",
    "    order_ids = df_ordered.order_id.unique().tolist()\n",
    "    for order_id in order_ids:\n",
    "        temp_df = df_ordered.query(\"order_id == \" + str(order_id))\n",
    "        # Need a copy as not to modify something we are iterarting over\n",
    "        first_row = temp_df.copy().head(1)\n",
    "        for i, temp_row in temp_df.iterrows():\n",
    "            temp_name = temp_row[item_name]\n",
    "            # If the feature is present, set it to 1\n",
    "            if temp_name in df.columns:\n",
    "                first_row[temp_name] = 1\n",
    "        # Add the aggregated entry\n",
    "        df = pd.concat([df, first_row])\n",
    "    df = df.drop(cols_to_drop, axis=1)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_feature(X, y, X_test, y_test):\n",
    "    n_features = X.shape[1]\n",
    "    # Not zero as some negative scores can happen\n",
    "    max_score = -100000\n",
    "    max_feature = None\n",
    "    for i in range(n_features):\n",
    "        feature = X.columns[i]\n",
    "        X_subset = X[[feature]]\n",
    "        X_test_subset = X_test[[feature]]\n",
    "        model = linear_model.LinearRegression()\n",
    "        model.fit(X_subset, y)\n",
    "        # R squared metric\n",
    "        score = model.score(X_test_subset, y_test)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_feature = feature\n",
    "    if max_feature is None :\n",
    "        print(\"Issue, max feature not found, size\", n_features)\n",
    "        print(X.columns.values)\n",
    "    return (max_score, max_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a very brute force way computing all possibilities of finding the solution with the highest score\n",
    "def order_best_features_and_score(X_train, y_train, X_test, y_test):\n",
    "    n_features = X_train.shape[1]\n",
    "    model_scores = [0]\n",
    "    best_features = []\n",
    "    best_score = -10000\n",
    "    X_selection = X_train.copy()\n",
    "    X_test_selection = X_test.copy()\n",
    "    X_subsets = pd.DataFrame(index=X_train.index)\n",
    "    X_test_subsets = pd.DataFrame(index=X_test.index)\n",
    "\n",
    "    for i in range(n_features):\n",
    "        max_score, next_best_feature = find_best_feature(X_selection, y_train, X_test_selection, y_test)\n",
    "\n",
    "        X_subset = X_selection[[next_best_feature]]\n",
    "        X_test_subset = X_test_selection[[next_best_feature]]\n",
    "    \n",
    "        X_subsets[next_best_feature] = X_subset\n",
    "        X_test_subsets[next_best_feature] = X_test_subset\n",
    "        \n",
    "        model = linear_model.LinearRegression()\n",
    "        model.fit(X_subsets, y_train)\n",
    "        score = model.score(X_test_subsets, y_test)\n",
    "        model_scores.append(score)\n",
    "        \n",
    "        score_increase_threshold = 0.01\n",
    "        if score > (best_score + score_increase_threshold):\n",
    "            best_score = score\n",
    "            best_features = X_subsets.columns.values\n",
    "\n",
    "        X_selection.drop([next_best_feature], axis=1, inplace=True)\n",
    "        X_test_selection.drop([next_best_feature], axis=1, inplace=True)\n",
    "    return (best_features, best_score, model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test and training split for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8ed09c4b3cb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_percentage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0morders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_days_to_next_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Can use this to estimate what would be ordered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0morders_with_no_next_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'days_to_next_order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Can split this into train and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-045628fe7d59>\u001b[0m in \u001b[0;36madd_days_to_next_order\u001b[0;34m(order_df)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0morders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0morders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"days_to_next_order\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_order\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnext_order_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_number\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3625\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3626\u001b[0;31m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3628\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_percentage = 0.2\n",
    "orders = add_days_to_next_order(orders)\n",
    "# Can use this to estimate what would be ordered\n",
    "orders_with_no_next_order = orders[orders['days_to_next_order'].isnull()]\n",
    "# Can split this into train and test\n",
    "orders_with_next_order = orders[~orders['days_to_next_order'].isnull()]\n",
    "train_orders, test_orders = train_test_split(orders_with_next_order, test_size=test_percentage)\n",
    "print(\"Training size is :\", train_orders.shape[0])\n",
    "print(\"Testing size is :\", test_orders.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test and training split for specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_orders = (orders\n",
    "                .groupby(\"user_id\")\n",
    "                .size()\n",
    "                .reset_index(name=\"count\")\n",
    "                .sort_values(by=['count'], ascending=False)\n",
    "               )\n",
    "# Get the most frequent user as this will have the most data associated with it\n",
    "most_frequeny_user_id =  count_orders.iloc[0].user_id\n",
    "single_user_orders = orders.query(\"user_id == \" + str(most_frequeny_user_id))\n",
    "single_user_orders = add_days_to_next_order(single_user_orders)\n",
    "user_orders_with_next_order = single_user_orders[~single_user_orders['days_to_next_order'].isnull()]\n",
    "user_train_orders, user_test_orders = train_test_split(user_orders_with_next_order, test_size=test_percentage)\n",
    "print(\"User id for single investigation :\", most_frequeny_user_id)\n",
    "print(\"Training size for single user is :\", user_train_orders.shape[0])\n",
    "print(\"Testing size for single user is is :\", user_test_orders.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Product and Aisle to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orders_prod, test_orders_prod = join_products(train_orders, test_orders)\n",
    "train_orders_prod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Investigation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = key_columns(\"product_id\")\n",
    "wanted_info_train = train_orders_prod[key_cols]\n",
    "wanted_info_test = test_orders_prod[key_cols]\n",
    "\n",
    "wanted_info_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Product Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only doing what products are currenty present in training set\n",
    "min_time_prod_appear = 3\n",
    "popular_products_ids = (wanted_info_train\n",
    "                        .groupby(\"product_id\")\n",
    "                        .size()\n",
    "                        .reset_index(name=\"count\")\n",
    "                        .query(\"count > \" + str(min_time_prod_appear))\n",
    "                        .product_id\n",
    "                        .tolist()\n",
    "                       )\n",
    "popular_products = products[products['product_id'].isin(popular_products_ids)]\n",
    "df_with_product_info_train = add_each_product_to_df(wanted_info_train, popular_products)\n",
    "df_with_product_info_test = add_each_product_to_df(wanted_info_test, popular_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"product_id\", \"product_name\", \"order_id\", \"department_id\", \"aisle_id\"]\n",
    "item = \"product_name\"\n",
    "df_prod_group_train = group_by_order_in_df(df_with_product_info_train, item, cols_to_drop)\n",
    "df_prod_group_test = group_by_order_in_df(df_with_product_info_test, item, cols_to_drop)\n",
    "\n",
    "df_prod_group_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data_to_features_and_value(df_prod_group_train, df_prod_group_test)\n",
    "# Where X are the features and Y is the days to next order (value trying to predict)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_feature(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features, best_score, model_scores = order_best_features_and_score(X_train, y_train, X_test, y_test)\n",
    "print(\"Best Score :\", best_score)\n",
    "print(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbfs, nbs, model_scores = order_best_features_and_score(X_train[best_features], y_train, X_test[best_features], y_test)\n",
    "print(\"Best Score :\", nbs)\n",
    "print(nbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aisle Rollup\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Desired Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = key_columns(\"aisle_id\")\n",
    "wanted_info_train = train_orders_prod[key_cols]\n",
    "wanted_info_test = test_orders_prod[key_cols]\n",
    "\n",
    "wanted_info_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Aisle Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_aisle_info_train = add_each_aisle_to_df(wanted_info_train)\n",
    "df_with_aisle_info_test = add_each_aisle_to_df(wanted_info_test)\n",
    "\n",
    "df_with_aisle_info_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the Aisle Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregates the data so we have days to next order with the aisles required checked\n",
    "cols_to_drop = [\"aisle\", \"aisle_id\", \"order_id\"]\n",
    "item = \"aisle\"\n",
    "df_aisle_group_train = group_by_order_in_df(df_with_aisle_info_train, item, cols_to_drop)\n",
    "df_aisle_group_test = group_by_order_in_df(df_with_aisle_info_test, item, cols_to_drop)\n",
    "\n",
    "df_aisle_group_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_data_to_features_and_value(df_aisle_group_train, df_aisle_group_test)\n",
    "# Where X are the features and Y is the days to next order (value trying to predict)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best feature/aisle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best_feature(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best features in Order and calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features, best_score, model_scores = order_best_features_and_score(X_train, y_train, X_test, y_test)\n",
    "print(\"Best Score :\", best_score)\n",
    "print(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbfs, nbs, model_scores = order_best_features_and_score(X_train[best_features], y_train, X_test[best_features], y_test)\n",
    "print(\"Best Score :\", nbs)\n",
    "print(nbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnbfs, nnbs, model_scores = order_best_features_and_score(X_train[best_features], y_train, X_train[best_features], y_train)\n",
    "print(\"New Best Score :\", nnbs)\n",
    "print(nnbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific User Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the User\n",
    "train_orders_prod, test_orders_prod = join_products(user_train_orders, user_test_orders)\n",
    "wanted_info_train = train_orders_prod[key_cols]\n",
    "wanted_info_test = test_orders_prod[key_cols]\n",
    "df_with_aisle_info_train = add_each_aisle_to_df(wanted_info_train)\n",
    "df_with_aisle_info_test = add_each_aisle_to_df(wanted_info_test)\n",
    "cols_to_drop = [\"aisle\", \"aisle_id\", \"order_id\"]\n",
    "item = \"aisle\"\n",
    "df_aisle_group_train = group_by_order_in_df(df_with_aisle_info_train, item, cols_to_drop)\n",
    "df_aisle_group_test = group_by_order_in_df(df_with_aisle_info_test, item, cols_to_drop)\n",
    "X_train, y_train, X_test, y_test = split_data_to_features_and_value(df_aisle_group_train, df_aisle_group_test)\n",
    "best_features, best_score, model_scores = order_best_features_and_score(X_train, y_train, X_test, y_test)\n",
    "print(\"Best Score :\", best_score)\n",
    "print(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features, best_score, model_scores = order_best_features_and_score(X_train[best_features], y_train, X_test[best_features], y_test)\n",
    "print(\"Best Score :\", best_score)\n",
    "print(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Score versus features\")\n",
    "plt.xlabel('Number of features') \n",
    "plt.ylabel('R squared')\n",
    "plt.plot(model_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW WE WANT TO USE PCA/REGULARISATION AND REMOVE SOME UNNEEDED INFO/AISLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONT FORGET TO MEAN CENTRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
